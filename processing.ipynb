{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the api key for<br> Embedding ( we would use it for retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai # For embedding for the retrieval\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key='YOUR_GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the prompt of the user<br>and matching the requirements<br>to the available data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'What is c ++ ?'\n",
      "Detected Language: C++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import json\n",
    "\n",
    "# Define the list of programming languages\n",
    "TABS_COL = ['C++', 'C Sharp', 'Java', 'JavaScript', 'Python', 'Mojo', 'Rust']\n",
    "\n",
    "class LanguageDetector(BaseModel):\n",
    "    \"\"\"Pydantic model to parse the language detection result.\"\"\"\n",
    "    language: Optional[str] = Field(\n",
    "        description=\"The detected programming language or None if no match\"\n",
    "    )\n",
    "\n",
    "def create_language_detection_prompt() -> PromptTemplate:\n",
    "    parser = PydanticOutputParser(pydantic_object=LanguageDetector)\n",
    "    template = \"\"\"You are an assistant tasked with identifying if a user's question is related to one of the following programming languages: {language_list}. \n",
    "If the question is related to one of these languages, respond with the language name; otherwise, respond with 'none'. \n",
    "Ensure your response contains only the language name or 'none' without any additional text.\n",
    "Question: {question}\n",
    "Response: {format_instructions}\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\", \"language_list\"],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        },\n",
    "        output_parser=parser\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def detect_programming_language(user_prompt: str) -> Optional[str]:\n",
    "    # Ensure the Google API key is set\n",
    "    if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "        raise ValueError(\"Please set the GOOGLE_API_KEY environment variable\")\n",
    "    \n",
    "    # Initialize the language detection prompt\n",
    "    prompt = create_language_detection_prompt()\n",
    "    \n",
    "    # Initialize the Gemini Flash LLM\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro\",\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    # Create the chain\n",
    "    chain = prompt | llm\n",
    "    \n",
    "    try:\n",
    "        # Invoke the chain\n",
    "        result = chain.invoke({\n",
    "            \"question\": user_prompt,\n",
    "            \"language_list\": \", \".join(TABS_COL)\n",
    "        })   \n",
    "        return json.loads(result.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting language: {e}\")\n",
    "        return None\n",
    "# Set your Google API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GEMINI_API_KEY\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "test_prompts = [\n",
    "    \"What is c ++ ?\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    detected_language = detect_programming_language(prompt)\n",
    "    print(f\"Prompt: '{prompt}'\\nDetected Language: {detected_language['language']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detected_language['language'] in TABS_COL :\n",
    "    print('in')\n",
    "else :\n",
    "    print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the matched document <br>from the prompt of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def load_rag_system(folder_path):\n",
    "    # Load FAISS index\n",
    "    index = faiss.read_index(os.path.join(folder_path, \"index.faiss\"))\n",
    "    \n",
    "    # Load documents (using JSON in this example)\n",
    "    with open(os.path.join(folder_path, \"documents.json\"), \"r\") as f:\n",
    "        documents = json.load(f)\n",
    "    \n",
    "    return index, documents\n",
    "\n",
    "index , documents_json= load_rag_system(detected_language['language'])\n",
    "\n",
    "sorted_data = sorted(documents_json.values(), key=lambda x: x['doc_id'])\n",
    "\n",
    "# Extract the 'text' values from the sorted data\n",
    "documents = [item['text'] for item in sorted_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the retriever of the chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def embed_text(text):\n",
    "    \"\"\"Embed text using Gemini's embedding-001 model.\"\"\"\n",
    "    embedding_result = genai.embed_content(\n",
    "            model='models/embedding-001',\n",
    "            content=text,\n",
    "            task_type='retrieval_query'\n",
    "        )\n",
    "    return embedding_result\n",
    "\n",
    "\n",
    "\n",
    "def retriever(query, k=3):\n",
    "    embedding_result = embed_text(query)\n",
    "    query_embedding = np.array(embedding_result['embedding']).astype('float32').reshape(1, -1)\n",
    "    \n",
    "    # Normalize the query vector\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    \n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    retrieved_docs = [documents[i] for i in indices[0]]\n",
    "    return retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt engeneering and the final call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, retrieved_docs):\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
    "    \n",
    "\n",
    "\n",
    "    prompt = f\"\"\"Given the context and query, extract the most relevant facts:\n",
    "    Context:\n",
    "    {' '.join(retrieved_docs)}\n",
    "    Query: {query}\n",
    "    Provide a concise, factual response.\"\"\"\n",
    "\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "query = \"what What do you think about c++ ?\"\n",
    "retrieved_docs = retriever(query)\n",
    "response = generate_response(query, retrieved_docs)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
